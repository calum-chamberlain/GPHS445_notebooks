{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Obspy\n",
    "\n",
    "Obspy is a Python package for seismology. It contains a wide range of tools, from fundamental input/output (IO) functions, up to higher\n",
    "level functions including noise analysis, beamforming and wrappers for travel-time calculations.  Obspy has rapidly gained popularity,\n",
    "as of February 2019, Obspy version 1.1.0 had been installed from conda-forge 11,720 times in the 3 months that it was the current version.\n",
    "\n",
    "## Python\n",
    "\n",
    "<img alt=\"Python logo\" align=\"right\" style=\"width:40%\" src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\">\n",
    "\n",
    "Python as a language is widely used, both within the scientific community and in more applied work. It is also open-source, meaning that\n",
    "the licence limitations of something like Matlab are not an issue.  Because Python is widely used there are some fantastic libraries,\n",
    "meaning that you do not need to re-invent the wheel - someone has probably solved your problem already - meaning you can focus on\n",
    "doing science. Furthermore, because Python is used beyond academia, it is a useful, transferable language to learn.\n",
    "\n",
    "Python is an interpreted language, meaning that you do not need to actively compile code to machine code before executing your core\n",
    "(unlike languages like C or Fortran). This means that you can rapidly test short ideas, and allows us to make use of things like\n",
    "Jupyter notebooks and the iPython interpretter.  In general interpreted languages are slower than compilled languages, and this\n",
    "is generally true for Python as well.  However, because Python is simple to extend with compiled languages (particularly C), Python\n",
    "provide a good *glue* between faster code components.  It is normal to convert time-critical sections of code to C and link these\n",
    "to a Python library. Numpy makes good use of this, and links some very fast compiled maths libraries (LAPACK and BLAS) in to Python.\n",
    "\n",
    "## Obspy\n",
    "\n",
    "<img alt=\"Obspy logo\" align=\"right\" style=\"width:40%\" src=\"https://raw.github.com/obspy/website/master/logo/obspy_logo_full_highres.png\">\n",
    "\n",
    "Obspy is actively maintained, developed and tested by an international group of seismologists.  Obspy also implements a good \n",
    "*continuous integration* workflow, whereby any proposed changes to the package are tested before they are accepted. The complete\n",
    "package is also tested prior to release, ensuring that Obspy does what it is supposed to. This kind of testing is incredibly\n",
    "important, and, while it does not guarantee correctness, it is a very necessary step to test code to ensure that it does what\n",
    "you expect it to.  Obspy also has fairly extensive documentation and good examples and tutorials.\n",
    "\n",
    "This notebook provides a really brief overview of some of the \"every-day\" functionality of Obspy that you will use within this\n",
    "course.  We will cover:\n",
    "- Reading and writing seismic data\n",
    "- Plotting seismic data\n",
    "- Filtering seismic data\n",
    "- Plotting spectrograms\n",
    "- Getting data from data centres\n",
    "- Reading in event data\n",
    "- Accesing relevant event information within a catalog\n",
    "- Plotting earthquake maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook set-up\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading seismic data\n",
    "\n",
    "Obspy provides a nice plug-in system for reading various seismic data formats.  As part of this\n",
    "obspy will attempt to auto-recognise your data format and read it. As long as you know where the\n",
    "data are, you have a good chance of being able to read it.\n",
    "\n",
    "We will try reading in some data from the Data directory which should have come with these notebooks.  The data we will read is a multiplexed miniseed file, which has been compressed using STEIM2 compression.\n",
    "Multiplexed means that it contains data from multiple channels, miniseed is a standard seismic data format\n",
    "used extensively by data-centres for storing waveform data, and STEIM2 is a form of compression.  The data\n",
    "are from five stations in New Zealand close to the Kaikoura M7.8 earthquake epicenter, and show the seconds\n",
    "before the mainshock and the first arrivals.  The stations use broadband seismometers and suffer\n",
    "from clipping during the Kaikoura wavetrain.  We will plot just the vertical components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Trace(s) in Stream:\n",
      "NZ.GVZ.10.HHE | 2016-11-13T11:01:42.348393Z - 2016-11-13T11:04:11.468393Z | 100.0 Hz, 14913 samples\n",
      "NZ.GVZ.10.HHN | 2016-11-13T11:01:45.528393Z - 2016-11-13T11:04:11.968393Z | 100.0 Hz, 14645 samples\n",
      "NZ.GVZ.10.HHZ | 2016-11-13T11:01:43.618393Z - 2016-11-13T11:04:11.168393Z | 100.0 Hz, 14756 samples\n",
      "NZ.KHZ.10.HHE | 2016-11-13T11:01:45.958389Z - 2016-11-13T11:04:11.738389Z | 100.0 Hz, 14579 samples\n",
      "NZ.KHZ.10.HHN | 2016-11-13T11:01:42.968389Z - 2016-11-13T11:04:11.878389Z | 100.0 Hz, 14892 samples\n",
      "NZ.KHZ.10.HHZ | 2016-11-13T11:01:44.608389Z - 2016-11-13T11:04:11.528389Z | 100.0 Hz, 14693 samples\n",
      "NZ.LTZ.10.HHE | 2016-11-13T11:01:44.968393Z - 2016-11-13T11:04:11.918393Z | 100.0 Hz, 14696 samples\n",
      "NZ.LTZ.10.HHN | 2016-11-13T11:01:42.218393Z - 2016-11-13T11:04:11.878393Z | 100.0 Hz, 14967 samples\n",
      "NZ.LTZ.10.HHZ | 2016-11-13T11:01:40.638393Z - 2016-11-13T11:04:11.558393Z | 100.0 Hz, 15093 samples\n",
      "NZ.THZ.10.HHE | 2016-11-13T11:01:42.713199Z - 2016-11-13T11:04:11.303199Z | 100.0 Hz, 14860 samples\n",
      "NZ.THZ.10.HHN | 2016-11-13T11:01:45.333198Z - 2016-11-13T11:04:11.843198Z | 100.0 Hz, 14652 samples\n",
      "NZ.THZ.10.HHZ | 2016-11-13T11:01:45.493198Z - 2016-11-13T11:04:11.633198Z | 100.0 Hz, 14615 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bbfb8f64c44a59bf5f6cb583f7dbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calumch/miniconda3/envs/gphs445/lib/python3.7/site-packages/obspy/imaging/util.py:275: UserWarning: AutoDateLocator was unable to pick an appropriate interval for this date range. It may be necessary to add an interval value to the AutoDateLocator's intervald dictionary. Defaulting to 30.\n",
      "  plt.setp(ax.get_xticklabels(), fontsize='small')\n",
      "/home/calumch/miniconda3/envs/gphs445/lib/python3.7/site-packages/obspy/imaging/waveform.py:817: UserWarning: AutoDateLocator was unable to pick an appropriate interval for this date range. It may be necessary to add an interval value to the AutoDateLocator's intervald dictionary. Defaulting to 30.\n",
      "  plt.setp(ax.get_xticklabels(), fontsize='small',\n"
     ]
    }
   ],
   "source": [
    "from obspy import read\n",
    "\n",
    "st = read(\"Data/kaikoura_geonet.ms\")\n",
    "print(st)\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "st.select(component=\"Z\").plot(equal_scale=False, fig=plt.figure())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get lots of information from these streams (a Stream in obspy is a list of channels of data,\n",
    "each channel of data is referred to as a *Trace*).  We will look at the information for the vertical\n",
    "channel of station LTZ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NZ.LTZ.10.HHZ | 2016-11-13T11:01:40.638393Z - 2016-11-13T11:04:11.558393Z | 100.0 Hz, 15093 samples\n"
     ]
    }
   ],
   "source": [
    "tr = st.select(station=\"LTZ\", channel=\"HHZ\")\n",
    "# Select returns a stream of traces that match your selection.\n",
    "# There is only one trace matching LTZ, channel HHZ, so we will\n",
    "# just take that trace using standard Python indexing\n",
    "tr = tr[0]\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traces have two fundamental attributes: `data` and `stats`.  `data` is just a numpy array of\n",
    "values that represent the waveform held. `stats` contains header information associated\n",
    "with the data, including the start-time, end-time, station and channel information, and\n",
    "can contain a record of the processing done to the data.\n",
    "\n",
    "Lets look at the `stats` for this trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         network: NZ\n",
      "         station: LTZ\n",
      "        location: 10\n",
      "         channel: HHZ\n",
      "       starttime: 2016-11-13T11:01:40.638393Z\n",
      "         endtime: 2016-11-13T11:04:11.558393Z\n",
      "   sampling_rate: 100.0\n",
      "           delta: 0.01\n",
      "            npts: 15093\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 72, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 512, 'filesize': 456704})\n"
     ]
    }
   ],
   "source": [
    "print(tr.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Do all the traces that we read in start and end at the same time? \n",
    "\n",
    "You can access individual attributes of the `stats` by writing `tr.stats.attribute`, for example,\n",
    "the sampling rate is accessed using `tr.stats.sampling_rate`.\n",
    "\n",
    "These data were downloaded from the GeoNet FDSN client without any changes to them, with a request \n",
    "to start and end at the same times. However, often data-centers will not provide exactly what you \n",
    "wanted to make it more efficient for them to supply you information.  You should check that you \n",
    "get what you ask for!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data\n",
    "\n",
    "We can write this data out to a \n",
    "[range of formats](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.write.html#supported-formats), \n",
    "for now we will try writing to SAC format.  SAC is the Seismic Analysis Code, and is both a data format and\n",
    "a code-base for data analysis.  The SAC data format does not support multiplexing, so we will write one\n",
    "trace per file, using a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to Data/NZ.GVZ.10.HHE.SAC\n",
      "Writing to Data/NZ.GVZ.10.HHN.SAC\n",
      "Writing to Data/NZ.GVZ.10.HHZ.SAC\n",
      "Writing to Data/NZ.KHZ.10.HHE.SAC\n",
      "Writing to Data/NZ.KHZ.10.HHN.SAC\n",
      "Writing to Data/NZ.KHZ.10.HHZ.SAC\n",
      "Writing to Data/NZ.LTZ.10.HHE.SAC\n",
      "Writing to Data/NZ.LTZ.10.HHN.SAC\n",
      "Writing to Data/NZ.LTZ.10.HHZ.SAC\n",
      "Writing to Data/NZ.THZ.10.HHE.SAC\n",
      "Writing to Data/NZ.THZ.10.HHN.SAC\n",
      "Writing to Data/NZ.THZ.10.HHZ.SAC\n"
     ]
    }
   ],
   "source": [
    "for trace in st:\n",
    "    filename = \"Data/{0}.SAC\".format(trace.id)  # The id is the SEED ID\n",
    "    print(\"Writing to {0}\".format(filename))\n",
    "    trace.write(filename=filename, format=\"SAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Read back in the SAC data you have just written - do you see any difference in the `stats`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting seismic data\n",
    "\n",
    "We have already seen that we can easily plot seismic data using the `.plot` method on a `Stream`.\n",
    "We can do the same with `Trace`s.  We can also use `starttime` and `endtime` arguments to only\n",
    "plot a section of data.  This will also demonstrate the use of Obspy's `UTCDateTime` object.  This\n",
    "holds date-time information, and extends Python's native `datetime` functionality to greater precision\n",
    "and back further in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2c76851b734d6c92b4c3be616684ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from obspy import UTCDateTime\n",
    "\n",
    "tr.plot(starttime=UTCDateTime(2016, 11, 13, 11, 2, 30),\n",
    "        endtime=UTCDateTime(2016, 11, 13, 11, 3, 30),\n",
    "        fig=plt.figure())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the first arriving P-wave from the Kaikoura mainshock and the subsequent growth of amplitudes\n",
    "as the earthquake gets going.\n",
    "\n",
    "For fun, lets zoom right in on the few seconds before the P-wave..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11bc254086a440ba54c8c0d5551be9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr.plot(starttime=UTCDateTime(2016, 11, 13, 11, 2, 55),\n",
    "        endtime=UTCDateTime(2016, 11, 13, 11, 3, 7, 630000),\n",
    "        fig=plt.figure())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the background long-period noise recorded by the broadband seismometer. However,\n",
    "over-printing it is a high-frequency signal, before Kaikoura ruptured (I selected the endtime to just\n",
    "catch the P-arrival from Kaikoura)...  \n",
    "\n",
    "Lets see if we can clean up those data by filtering.  We will filter the longer time-series, \n",
    "remembering to detrend the data first, and applying a taper to stabalise the filter.\n",
    "All of these operations can be chained together because each method returns a trace itself. See the\n",
    "[obspy docs](docs.obspy.org) to see the options available for these methods.  We copy the data first\n",
    "because these methods work *in-place* on the data, meaning the original data is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calumch/miniconda3/envs/gphs445/lib/python3.7/site-packages/obspy/core/trace.py:2111: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not np.issubdtype(self.data.dtype, float):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b52def74ff4c8e848cc0642ce2938d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr.copy().detrend('linear').taper(\n",
    "    max_length=2, max_percentage=20).filter(\"highpass\", corners=4, freq=2.0).plot(\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11, 2, 55),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 3, 7, 625000),\n",
    "    fig=plt.figure())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see high-frequency arrivals, which turns out to be the P-wave of a foreshock in a \n",
    "similar location to the mainshock, but at a much lower magnitude.\n",
    "\n",
    "**Exercise:** Can you find this foreshock on the other stations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "We have already seen the `.filter` method that provides us with simple access to filter.\n",
    "We can specify a range of options for that method, which you can investigate on the\n",
    "[docs page](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.filter.html#obspy.core.stream.Stream.filter) for the `.filter` method.  Key options are the filter type, the corner frequencies, and the\n",
    "number of corners.  The number of corners is equivalent to the filter order.\n",
    "\n",
    "Lets try lowpassing the data and seeing what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calumch/miniconda3/envs/gphs445/lib/python3.7/site-packages/obspy/core/trace.py:2111: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not np.issubdtype(self.data.dtype, float):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb29eb7fdbf4e85ae7fa135ecb998a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calumch/miniconda3/envs/gphs445/lib/python3.7/site-packages/obspy/imaging/util.py:275: UserWarning: AutoDateLocator was unable to pick an appropriate interval for this date range. It may be necessary to add an interval value to the AutoDateLocator's intervald dictionary. Defaulting to 30.\n",
      "  plt.setp(ax.get_xticklabels(), fontsize='small')\n",
      "/home/calumch/miniconda3/envs/gphs445/lib/python3.7/site-packages/obspy/imaging/waveform.py:817: UserWarning: AutoDateLocator was unable to pick an appropriate interval for this date range. It may be necessary to add an interval value to the AutoDateLocator's intervald dictionary. Defaulting to 30.\n",
      "  plt.setp(ax.get_xticklabels(), fontsize='small',\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "tr.copy().detrend('linear').taper(\n",
    "    max_percentage=20, max_length=2).filter(\n",
    "    \"lowpass\", corners=4, freq=1.0).plot(fig=plt.figure())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Bandpass the data between 2 and 10 Hz - don't forget to detrend and taper the data\n",
    "to stabalise the Fourier transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrograms\n",
    "\n",
    "Spectrogams plot the frequency content of a waveform in time. A common way of doing this\n",
    "is to chunk the data into sections and take the FFT of those sections. The result is an image\n",
    "with colours representing relative power of different frequencies through time.  Obspy\n",
    "provides a `.spectrogram` method to do this.  We will use this to look at the frequency content\n",
    "prior to the mainshock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d96daeb3e94ec489c2f564acdfeda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can extract the chunk of data that we want to look at using the trim method,\n",
    "# This cuts the data in-place, so we copy first.\n",
    "tr_foreshock = tr.copy().trim(\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11, 2, 55),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 3, 7, 625000))\n",
    "# Here we use a logarithmic amplitude scale using dbscale=True\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "tr_foreshock.spectrogram(dbscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see strong (bright colours) low-frequency energy throughout the waveform, which we knew just\n",
    "by looking at the waveforms.  There is also an increase in higher frequency energy corresponding\n",
    "to the arrival of the foreshock, as expected.  Spectrograms can be a useful way to look for changes\n",
    "in frequency content, which might be associated with signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from data centres\n",
    "\n",
    "For a long time, seismology has relied on open sharing of data - initially sharing phase\n",
    "arrival times to locate earthquakes, but more recently waveform data is being shared.  Data\n",
    "centres such as GeoNet, IRIS and others provide access via a range of webservices.  The most common\n",
    "is the FDSN (Federated Digital Seismograph Networks) protocol. Obspy provides access for a few\n",
    "protocols, but we will just use FDSN here.\n",
    "\n",
    "FDSN allows sharing of waveform data as well as event and station meta-data, making it a *one-stop-shop*\n",
    "for all your earthquake needs.  We will use this to get waveform data for a couple of other stations\n",
    "in New Zealand for the Kaikoura earthquake, as well as the event data for this earthquake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "NZ.APZ.10.HHE | 2016-11-13T10:59:56.268394Z - 2016-11-13T11:10:01.178394Z | 100.0 Hz, 60492 samples\n",
      "NZ.APZ.10.HHN | 2016-11-13T10:59:59.728394Z - 2016-11-13T11:10:00.978394Z | 100.0 Hz, 60126 samples\n",
      "NZ.APZ.10.HHZ | 2016-11-13T10:59:55.758394Z - 2016-11-13T11:10:00.938394Z | 100.0 Hz, 60519 samples\n"
     ]
    }
   ],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "client = Client(\"GEONET\")  # This tells the client where to ask for data from\n",
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"APZ\", location=\"10\", channel=\"HH?\",\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 10))\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That stream contains data from a station on Stewart Island. Note that FDSN queries support\n",
    "wildcards (the ? means any single character, a * means any string). \n",
    "Lets get data from another station on Chatham Island, and one in the Kermadecs.  Note that streams\n",
    "support addition, which will append streams together: below we use the in-place addition\n",
    "operator `+=` to add streams to the stream we already have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Trace(s) in Stream:\n",
      "NZ.APZ.10.HHE  | 2016-11-13T10:59:56.268394Z - 2016-11-13T11:10:01.178394Z | 100.0 Hz, 60492 samples\n",
      "NZ.APZ.10.HHN  | 2016-11-13T10:59:59.728394Z - 2016-11-13T11:10:00.978394Z | 100.0 Hz, 60126 samples\n",
      "NZ.APZ.10.HHZ  | 2016-11-13T10:59:55.758394Z - 2016-11-13T11:10:00.938394Z | 100.0 Hz, 60519 samples\n",
      "NZ.GLKZ.10.HHE | 2016-11-13T10:59:58.173129Z - 2016-11-13T11:10:00.473129Z | 100.0 Hz, 60231 samples\n",
      "NZ.GLKZ.10.HHN | 2016-11-13T10:59:58.343129Z - 2016-11-13T11:10:01.933129Z | 100.0 Hz, 60360 samples\n",
      "NZ.GLKZ.10.HHZ | 2016-11-13T10:59:59.163129Z - 2016-11-13T11:10:00.813129Z | 100.0 Hz, 60166 samples\n",
      "NZ.CTZ.10.HHE  | 2016-11-13T10:59:58.738385Z - 2016-11-13T11:10:00.298385Z | 100.0 Hz, 60157 samples\n",
      "NZ.CTZ.10.HHN  | 2016-11-13T10:59:57.998385Z - 2016-11-13T11:10:00.448385Z | 100.0 Hz, 60246 samples\n",
      "NZ.CTZ.10.HHZ  | 2016-11-13T10:59:59.478385Z - 2016-11-13T11:10:00.118385Z | 100.0 Hz, 60065 samples\n"
     ]
    }
   ],
   "source": [
    "for station in ['GLKZ', \"CTZ\"]:\n",
    "    st += client.get_waveforms(\n",
    "        network=\"NZ\", station=station, location=\"10\", channel=\"HH?\",\n",
    "        starttime=UTCDateTime(2016, 11, 13, 11),\n",
    "        endtime=UTCDateTime(2016, 11, 13, 11, 10))\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get the event data for the Kaikoura mainshock, we will use the filter methods provided by\n",
    "`.get_events` to select only those events in the GeoNet catalog over magnitude 7 on the hour\n",
    "around Kaikoura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Event(s) in Catalog:\n",
      "2016-11-13T11:02:56.346094Z | -42.693, +173.022 | 7.820379733 Mw(mB) | manual\n"
     ]
    }
   ],
   "source": [
    "catalog = client.get_events(\n",
    "    minmagnitude=7,    \n",
    "    starttime=UTCDateTime(2016, 11, 13, 11),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 12))\n",
    "print(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a catalog object containing one event.  Obspy supports reading and writing\n",
    "catalogs in a range of formats, but the most common, and recommended for portability is QuakeML, \n",
    "however, large catalogs can be slow to read or write to and from QuakeML.\n",
    "\n",
    "To start off, lets look at what this catalog contains.  A catalog is essentially a list of events,\n",
    "each event has a lot of information in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event:\t2016-11-13T11:02:56.346094Z | -42.693, +173.022 | 7.820379733 Mw(mB) | manual\n",
      "\n",
      "\t            resource_id: ResourceIdentifier(id=\"smi:nz.org.geonet/2016p858000\")\n",
      "\t             event_type: 'earthquake'\n",
      "\t          creation_info: CreationInfo(agency_id='WEL(GNS_Primary)', author='scevent@akeqp01.geonet.org.nz', creation_time=UTCDateTime(2016, 11, 13, 11, 3, 27, 886738))\n",
      "\t    preferred_origin_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Origin#20161116052725.210418.52361\")\n",
      "\t preferred_magnitude_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Magnitude#20161116052734.469407.55057\")\n",
      "\t                   ---------\n",
      "\t     event_descriptions: 1 Elements\n",
      "\t               comments: 1 Elements\n",
      "\t                  picks: 189 Elements\n",
      "\t             amplitudes: 200 Elements\n",
      "\t                origins: 1 Elements\n",
      "\t             magnitudes: 5 Elements\n",
      "\t     station_magnitudes: 200 Elements\n"
     ]
    }
   ],
   "source": [
    "print(catalog[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this event has a lot of picks (189), and lots of amplitude picks associated with it.\n",
    "There are also five different magnitudes, and 200 station magnitudes. Lets look at the \n",
    "different magnitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitude\n",
      "\t                     resource_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Magnitude#20161116052734.390205.54854\")\n",
      "\t                             mag: 7.36346279 [uncertainty=0.2497736769]\n",
      "\t                  magnitude_type: 'MLv'\n",
      "\t                       origin_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Origin#20161116052725.210418.52361\")\n",
      "\t                       method_id: ResourceIdentifier(id=\"smi:nz.org.geonet/trimmed_mean\")\n",
      "\t                   station_count: 58\n",
      "\t                   creation_info: CreationInfo(agency_id='WEL(GNS_Primary)', author='annak@akeqx01.geonet.org.nz', creation_time=UTCDateTime(2016, 11, 16, 5, 27, 34, 390299))\n",
      "\t                            ---------\n",
      "\t station_magnitude_contributions: 76 Elements\n",
      "Magnitude\n",
      "\t                     resource_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Magnitude#20161116052734.422399.54931\")\n",
      "\t                             mag: 7.763918273 [uncertainty=0.3423031014]\n",
      "\t                  magnitude_type: 'ML'\n",
      "\t                       origin_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Origin#20161116052725.210418.52361\")\n",
      "\t                       method_id: ResourceIdentifier(id=\"smi:nz.org.geonet/trimmed_mean\")\n",
      "\t                   station_count: 57\n",
      "\t                   creation_info: CreationInfo(agency_id='WEL(GNS_Primary)', author='annak@akeqx01.geonet.org.nz', creation_time=UTCDateTime(2016, 11, 16, 5, 27, 34, 422435))\n",
      "\t                            ---------\n",
      "\t station_magnitude_contributions: 75 Elements\n",
      "Magnitude\n",
      "\t                     resource_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Magnitude#20161116052734.443641.55007\")\n",
      "\t                             mag: 7.692599795 [uncertainty=0.190699481]\n",
      "\t                  magnitude_type: 'mB'\n",
      "\t                       origin_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Origin#20161116052725.210418.52361\")\n",
      "\t                       method_id: ResourceIdentifier(id=\"smi:nz.org.geonet/mean\")\n",
      "\t                   station_count: 18\n",
      "\t               evaluation_status: 'confirmed'\n",
      "\t                   creation_info: CreationInfo(agency_id='WEL(GNS_Primary)', author='annak@akeqx01.geonet.org.nz', creation_time=UTCDateTime(2016, 11, 16, 5, 27, 34, 443684))\n",
      "\t                            ---------\n",
      "\t station_magnitude_contributions: 49 Elements\n",
      "Magnitude\n",
      "\t    resource_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Magnitude#20161116052734.469407.55057\")\n",
      "\t            mag: 7.820379733 [uncertainty=0.4]\n",
      "\t magnitude_type: 'Mw(mB)'\n",
      "\t      origin_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Origin#20161116052725.210418.52361\")\n",
      "\t  station_count: 37\n",
      "\t  creation_info: CreationInfo(agency_id='WEL(GNS_Primary)', author='annak@akeqx01.geonet.org.nz', creation_time=UTCDateTime(2016, 11, 16, 5, 27, 34, 469371))\n",
      "Magnitude\n",
      "\t    resource_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Origin#20161116052725.210418.52361#netMag.M\")\n",
      "\t            mag: 7.762542146\n",
      "\t magnitude_type: 'M'\n",
      "\t      origin_id: ResourceIdentifier(id=\"smi:nz.org.geonet/Origin#20161116052725.210418.52361\")\n",
      "\t      method_id: ResourceIdentifier(id=\"smi:nz.org.geonet/weighted_average\")\n",
      "\t  station_count: 58\n",
      "\t  creation_info: CreationInfo(agency_id='WEL(GNS_Primary)', author='scmag@akeqp01.geonet.org.nz', creation_time=UTCDateTime(2016, 11, 16, 5, 30, 21, 914032))\n"
     ]
    }
   ],
   "source": [
    "for magnitude in catalog[0].magnitudes:\n",
    "    print(magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeoNet will often calculate a few different magnitudes for events - we will talk about what these all\n",
    "mean later in the course.  For now it is worth noting that magnitudes based on body-wave amplitude\n",
    "do not usually give good results for large earthquakes.\n",
    "\n",
    "Lets look at what information is with one of the picks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick\n",
      "\t     resource_id: ResourceIdentifier(id=\"smi:nz.org.geonet/20161113.110307.63-AIC-NZ.LTZ.10.HHZ\")\n",
      "\t            time: UTCDateTime(2016, 11, 13, 11, 3, 7, 638393)\n",
      "\t     waveform_id: WaveformStreamID(network_code='NZ', station_code='LTZ', channel_code='HHZ', location_code='10')\n",
      "\t       filter_id: ResourceIdentifier(id=\"smi:nz.org.geonet/BW(4,2.5,15)\")\n",
      "\t       method_id: ResourceIdentifier(id=\"smi:nz.org.geonet/AIC\")\n",
      "\t      phase_hint: 'P'\n",
      "\t evaluation_mode: 'automatic'\n",
      "\t   creation_info: CreationInfo(agency_id='WEL(GNS_Primary)', author='scautopick@akeqp01.geonet.org.nz', creation_time=UTCDateTime(2016, 11, 13, 11, 3, 10, 430324))\n"
     ]
    }
   ],
   "source": [
    "print(catalog[0].picks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the pick we get told what channel it is assciated with (`waveform_id`), what phase it is likely\n",
    "to be (`phase_hint`), what the pick-time is (`time`), who made the pick (`creation_info.author`, in\n",
    "this case it was the seiscomp autopicker) as well as other useful info.  This kind of extensive\n",
    "information makes it possible to evaluate the quality of the pick and try to reproduce the pick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting event maps\n",
    "\n",
    "Lets get some more events and see where they have been located.  To do this we will drop the minimum\n",
    "magnitude down from our previous query, which should give us a lot of aftershocks, even in the first\n",
    "hour.  Later we will talk about Omori aftershock decay and how we expect most aftershocks early\n",
    "in the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0f88f26ed54eb7abb5028994c2ea15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catalog = client.get_events(\n",
    "    minmagnitude=4,    \n",
    "    starttime=UTCDateTime(2016, 11, 13, 11),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 12))\n",
    "fig = catalog.plot(\n",
    "    projection=\"local\", resolution=\"h\", label=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot earthquake epicenters are plotted as dots, scaled by magnitude. The colour-scale\n",
    "shows the depth (in km) of the hypocenter.\n",
    "\n",
    "We are not restricted to local catalogs though: lets try downloading the global catalog from IRIS\n",
    "above magnitude 6 for 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc16326da81421db79c993da1f5e258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = Client(\"IRIS\")\n",
    "catalog = client.get_events(\n",
    "    minmagnitude=6.5,\n",
    "    starttime=UTCDateTime(2016, 1, 1),\n",
    "    endtime=UTCDateTime(2017, 1, 1))\n",
    "catalog.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That concludes our short tour of obspy! There is a **lot** more useful code in obspy, and\n",
    "if you want to do something with seismic data or event data it is worth looking their first\n",
    "before you write your own code.  The [obspy tutorials](https://docs.obspy.org/tutorial/) demonstrates\n",
    "a lot of other features, and the documentation is quite extensive. Search their docs for help when you\n",
    "need it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
