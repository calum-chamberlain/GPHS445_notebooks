{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to processing seismic data\n",
    "\n",
    "In this first notebook we will cover some basics of getting, reading, writing and processing passive seismic data.  One of the main goals of this notebook is to get you familiar with using [ObsPy](https://docs.obspy.org/), which is a Python package for Observational Seismology (and it is very helpful!).\n",
    "\n",
    "This notebook covers the following main topics:\n",
    "1. Seismic data conventions;\n",
    "2. Downloading data from data-centres;\n",
    "3. Plotting waveforms;\n",
    "4. Reading local data;\n",
    "5. Basic processing (the theory will be covered in another notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Seismic data conventions\n",
    "\n",
    "Before we get into looking at seismic data we should know a little about how seismic data are stored and the naming conventions. We are just going to cover passive seismic data - active source data is a whole other kettle-of-fush.\n",
    "\n",
    "Passive seismic data are usually stored in either continuous or triggered files, where continuous files are in some standard data structure (consider the [GeoNet S3 archive](https://github.com/GeoNet/data-tutorials/tree/main/AWS_Open_Data#digital-waveform-data) on AWS) and don't have gaps (unless there is data missing). Triggered data, on the other hand, is stored in short chunks of data for particular events of interest (again GeoNet has examples of those in their [strong motion records](https://data.geonet.org.nz/seismic-products/strong-motion/volume-products/)). In either case, data are *usually* stored in a specific and standardised data format, the most common of these is [miniseed](https://ds.iris.edu/ds/nodes/dmc/data/formats/miniseed/). Useful data formats will contain not only the amplitude information recorded, but also some metadata about the station and channel that recorded it, the sampling rate of the data, and a few other useful things. Different formats store different metadata. [SAC](https://ds.iris.edu/files/sac-manual/manual/file_format.html) can store quite a lot of header information, but as you will have seen from ESCI451, in modern workflows we generally try to keep analytical results seperate from our raw data, so a lot of the extra metadata that can be stored in SAC *should* be stored in speerate files.\n",
    "\n",
    "You don't need to understand data formats much, in part because [obspy](https://docs.obspy.org/packages/obspy.core.html#example) make reading standard data formats really simple as yoiu will see later in this notebook. You don't usually need to even know the data format: obspy will work it out for you (yay! The obspy developers are awesome).\n",
    "\n",
    "What you do need to know, is how seismic data are named.\n",
    "\n",
    "### SEED convention\n",
    "Passive seismic data are named according to the [SEED naming convention](https://ds.iris.edu/ds/nodes/dmc/data/formats/seed-channel-naming/). This results in *seed ids* that are of the form `network.station.location.channel` where:\n",
    "- `network` is a two letter identifier of the network that the station is in (GeoNet's network code is NZ).\n",
    "- `station` is an identifier of five or fewer letters that name the station (note that this needs to be unique within the network)\n",
    "- `location` is a two character (typically numbers) identifier to specify the location of the sensor. The code doesn't relate to any physical quantity, but just identifies a single sensor location at a given station. For example stations in the NZ national network have a broadband sensor (usually with a location code 10, unless the sensor has moved) and a strong-motion sensor (usually with a location code 20, unless the sensor has moved). An example of this is station [PYZ](https://www.geonet.org.nz/data/network/sensor/PYZ). This is to signfify the difference between a site and the actual sensor location.\n",
    "- `channel` is a three character identifier that specifies the frequency band of the channel, the type of instrument, and the orientation respectively. See the [SEED naming convention](https://ds.iris.edu/ds/nodes/dmc/data/formats/seed-channel-naming/) for more details.\n",
    "\n",
    "Using this you can work out useful things like whether you are looking at a vertical or horizontal channel, what frequencies you might expect to see, and the rough gain of the system. Quantification of these details are provided in *instrument response* files and we will look at those in a few notebooks time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Accessing FDSN data\n",
    "\n",
    "[FDSN](https://www.fdsn.org/) stands for Federation of Digital Seismograph Networks, and is an organisation that aims to achieve good geographic seismographic coverage of the globe. Along the way to this goal the FDSN developed several standards which help to archive and distribute seismic data. It is fun to think that seismology was one of the worlds earliest truely international scientific endeavours: to be able to locate teleseismic earthquakes data from around the world is needed, so from very early on in seismology data were shared between institutions.\n",
    "\n",
    "For our purposes, the FDSN provides a really useful standard for data access through the [FDSN web services](https://www.fdsn.org/webservices/) specifications. You don't need to know the intricacies of this, but feel free to read up if you are interested in data sharing and access! The FDSN specification covers waveform and event data as well as station meta-data.\n",
    "\n",
    "ObsPy implements pythonic ways of accessing FDSN-compliant web-services through their [FDSN client](https://docs.obspy.org/packages/obspy.clients.fdsn.html). One such FDSN-compliant web-service is offered by [GeoNet](https://www.geonet.org.nz/data/tools/FDSN), meaning we can look at some NZ data very easily, yay!\n",
    "\n",
    "Lets start off by instantiating a Client that can access the GeoNet web-service.  You have to instantiate a new client for each different end-point (say you want data from GeoNet and IRIS, you will need to make two Clients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "client = Client(\"GEONET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of the available clients that ObsPy knows about can be found [here](https://docs.obspy.org/packages/obspy.clients.fdsn.html#id1), and includes the raspberry shake network that we might have connected our raspberry shakes to earlier! If we didn't, then you can check out the data for the Raspberry Shake in the Geophysics Vault on the 1st floor of cotton building [here](https://dataview.raspberryshake.org/#/AM/RAC6D/00/EHZ?streaming=on).\n",
    "\n",
    "We can get three types of data from FDSN-compliant web-services (although not all offer all three - RASPISHAKE only provides waveform data for example):\n",
    "1. Station meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings  # GeoNet doesn't fully specify the stationXML version and ObsPy complains, we can ignore that\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    inventory = client.get_stations(\n",
    "        network=\"NZ\", station=\"FOZ\", location=\"10\", channel=\"HHZ\")\n",
    "# This inventory contains a single network, we can run print(inventory) to see this, or we can look at that network\n",
    "print(inventory.networks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Event information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = client.get_events(eventid=\"2016p858000\")\n",
    "print(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Waveform information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to specify a start and end-time. To do that we use ObsPy's UTCDateTime object\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"FOZ\", location=\"10\", channel=\"HHZ\",\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 20))\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Basic plotting\n",
    "\n",
    "Obspy has nice quick ways to plot a few things, including waveforms. The object that we got from the `client.get_waveforms` call above is a [`Stream`](https://docs.obspy.org/tutorial/code_snippets/reading_seismograms.html). Check out the linked tutorial for more information on `Stream` objects.\n",
    "\n",
    "To get these plots to play nice in the notebooks (to have a zoomable window) we need to set up a figure first. However, outside of Jupyter you can just plot using:\n",
    "\n",
    "```python\n",
    "st.plot()\n",
    "```\n",
    "\n",
    "give it a go below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "# To make the figure zoomable we have to pass a figure to plot:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "fig = st.plot(fig=fig, show=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus points** what earthquake is this data for, and where is the seismograph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## An aside on time\n",
    "\n",
    "Seismic data are recorded at fairly high sampling rates (often > 50 samples per second, more on the effect of sampling rates later). To be able to work with that we need a fairly high precision way of representing times. ObsPy has it's own `UTCDateTime` class that handles times to the required precision. These are used throughout ObsPy and have some handy things, most notably, adding seconds to them!\n",
    "\n",
    "For example, to make a `UTCDateTime` object we can pass a year, month, day, hour, minute, second and nanosecond like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UTCDateTime(2017, 2, 11, 13, 12, 24, 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the [docs on UTCDateTime](https://docs.obspy.org/packages/autogen/obspy.core.utcdatetime.UTCDateTime.html) for more options.\n",
    "\n",
    "We can then do maths with them - we can add seconds directly, for example if I wanted a time 20.5 seconds after the time above I could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UTCDateTime(2017, 2, 11, 13, 12, 24, 4000) + 20.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need raw `datetime` objects (for example for plotting), then you can get one using the `.datetime` property of `UTCDateTime` objects, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sometime = UTCDateTime(2017, 2, 11, 13, 12, 24, 4000)\n",
    "sometime.datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting more data\n",
    "\n",
    "Now we know how time works (in ObsPy at least), you should be able to get some data for yourself. Use the `client.get_waveforms` method we used before, but this time get data for:\n",
    "- network: NZ\n",
    "- station: JCZ\n",
    "- channel: HHN\n",
    "- location: 10\n",
    "- starttime: 2016/11/13 00:00\n",
    "and length of one day (hint, just add 86400 seconds onto the starttime).\n",
    "\n",
    "Download and plot these data below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple stations\n",
    "\n",
    "We can get data for multiple stations and store it in an ObsPy `Stream`. One way to do that is to add `Stream`s together like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"FOZ\", location=\"10\", channel=\"HHZ\",\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 20))\n",
    "st += client.get_waveforms(\n",
    "    network=\"NZ\", station=\"JCZ\", location=\"10\", channel=\"HHZ\",\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 20))\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "_ = st.plot(fig=fig, show=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `Stream` has two `Trace`s in it - we can access individual `Trace`s using normal list indexing like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr = st[0]\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get data from multiple stations using *\"wildcard\"* queries, where a `*` counts for any string, and a `?` matches any letter. For example if we want all three HH channels from FOZ we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"FOZ\", location=\"10\", channel=\"HH?\",  # Note the ? in the channel argument\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 20))\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, lets put that all together and download 10 minutes of data for all stations within 100 km of the Kaikoura epicentre (GeoNet has it at -42.69, 173.02).\n",
    "\n",
    "To start with we can get an inventory of all the stations within 1 degree of a point using code like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    inv = client.get_stations(latitude=-42.69, longitude=173.02, maxradius=1, level=\"station\")\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is quite a lot of stations! Lets just restrict ourselves to broadband instruments with channels `HH?`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    inv = client.get_stations(latitude=-42.69, longitude=173.02, maxradius=1, level=\"station\", channel=\"HH?\")\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out this includes stations operating not within the time period we are interested in (around Kaikoura), we can specify another couple of arguments, `startbefore` and `endafter` to make sure that we only get stations that should have data when we want it.  I'm going to set a starttime and endtime variable that we can use later as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starttime = UTCDateTime(2016, 11, 13, 11)\n",
    "endtime = starttime + 10 * 60\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    inv = client.get_stations(\n",
    "        latitude=-42.29, longitude=173.02, maxradius=1, level=\"station\", channel=\"HH?\",\n",
    "        startbefore=starttime, endafter=endtime)\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we know what stations we want we can download them - we can use a loop for this!\n",
    "\n",
    "We will start with an empty `Stream` and add to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "from obspy import Stream\n",
    "\n",
    "st = Stream()\n",
    "for network in inv:  # The first level of the inventory hierachy\n",
    "    for station in network:  # The second level of the inventory hierachy\n",
    "        st += client.get_waveforms(\n",
    "            network=network.code, station=station.code, location=\"*\", channel=\"HH?\",\n",
    "            starttime=starttime, endtime=endtime)\n",
    "fig = plt.figure()\n",
    "_ = st.plot(fig=fig, show=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Those waveforms look horrible - who knows what is going on here?\n",
    "\n",
    "\n",
    "---\n",
    "## Metadata\n",
    "\n",
    "`Trace` objects contain not only the data, but also some useful metadata that explain the seismic data.  These are contained within the `trace.stats` attribute.  Lets look at one now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(st[0].stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us lots of useful information - the sampling rate, and sampling interval, the naming used for the station, the start and end time of the trace, and some information about how the data were processed and retrieved from the FDSN client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data for an event\n",
    "\n",
    "So we just downloaded data for one event - we could to this for any event, but the best way to do this is probably going to be using a function.\n",
    "\n",
    "To start with, the things that we needed were the location of the event, and the time of the event.  We can get that from the `Event` downloaded from the FDSN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat = client.get_events(eventid=\"2016p858000\")\n",
    "event = cat[0]  # A catalog is just a list of events with a few handy methods on top\n",
    "\n",
    "origin = event.preferred_origin()  # an event can contain multiple origins, but one is usually set as the best\n",
    "print(origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that there is lots of information in there, but crucially there is also `time`, `longitude` and `latitude`, that we need to specify the region and start and end time of our downloaded data.\n",
    "\n",
    "Try making a function that takes an event-id, a `Client` and a radius and downloads the broadband stations for that event.  I have started writing some psuedo-code below for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_for_event(event_id, client, maxradius, duration):\n",
    "    \"\"\"\n",
    "    Get data for broadband stations within maxradius of an event.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    event_id\n",
    "        event-id to get data for\n",
    "    client\n",
    "        FDSN client to get data from\n",
    "    maxradius\n",
    "        Maximum radius to get stations for in degrees\n",
    "    duration\n",
    "        Duration to download in seconds\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stream\n",
    "    \"\"\"\n",
    "    # Download the event of interest\n",
    "    \n",
    "    # Get the stations within maxradius of the event origin and operational during the time window of interest\n",
    "    # inv = client.get_stations\n",
    "    \n",
    "    # Download the waveforms for those stations\n",
    "    st = Stream()\n",
    "    #for network in inv:\n",
    "    #    for station in network:\n",
    "    \n",
    "    # Return the Stream!\n",
    "    return st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a function, use it to get the data for broadband stations within 200 km of the 2009 Dusky Sound Magnitude 7.8 earthquake, and plot the waveforms. Do you see the same clipping of high amplitudes that we saw with the Kaikoura earthquake?\n",
    "\n",
    "You can also try getting data from the strong motion stations (that have channel codes HN?) and see if they clip or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick look at frequency content\n",
    "\n",
    "Obspy also has a nice way to look at the frequency content of waveforms.  We can plot a waveforms [spectrogram](https://docs.obspy.org/tutorial/code_snippets/plotting_spectrograms.html) fairly simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"FOZ\", location=\"10\", channel=\"HHZ\",\n",
    "    starttime=UTCDateTime(2014, 11, 1, 0, 0),\n",
    "    endtime=UTCDateTime(2014, 11, 1, 0, 10))\n",
    "fig, ax = plt.subplots()\n",
    "_ = st.spectrogram(log=True, dbscale=True, axes=ax, show=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this is showing us is the power in each frequency band (along the y-axis) for every few samples in time (along the x-axis).  We will talk more about this in the lab on Fourier Analysis. For now, you need to know that warmer colours indicate more power - this station has most of it's power below 1 Hz, which is common for a time-period dominated by seismic noise. \n",
    "\n",
    "Lets compare that to when there was an earthquake nearby the site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"FOZ\", location=\"11\", channel=\"HHZ\",  # Location code changed for FOZ.\n",
    "    starttime=UTCDateTime(2021, 2, 2, 13, 40),\n",
    "    endtime=UTCDateTime(2021, 2, 2, 13, 50))\n",
    "fig, ax = plt.subplots()\n",
    "_ = st.spectrogram(log=True, dbscale=True, axes=ax, show=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should just be able to make out a little bright patch around x=850 around 10 Hz - that is the earthquake! Try zooming in to get a better look at that peak.\n",
    "\n",
    "Earthquakes generally start off emitting a broad range of frequencies, including much higher frequencies than noise.  Higher frequencies attenuate faster, so we don't usually record frequencies above 20 Hz for earthquakes recorded beyond a few km away.\n",
    "\n",
    "Try downloading some data that you are interested in and looking at the spectrogram - volcanoes produce some interesting frequencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reading local data\n",
    "\n",
    "We will mostly work with GeoNet data in this course, but you can also read local data in ObsPy.  You should have been provided with a file \"COSA_kaik.ms\" which contains data from SAMBA site COSA, between Fox Glacier and Franz Josef, for the day of the Kaikōura earthquake.\n",
    "\n",
    "You can read most common seismological data formats in ObsPy just by running:\n",
    "```python\n",
    "from obspy import read\n",
    "\n",
    "st = read(\"filename\")\n",
    "```\n",
    "where filename is the name of the file you want to read (the full-path!). \n",
    "\n",
    "Try this now with the data file provided, and plot the data and the spectrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read some local data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Basic processing\n",
    "\n",
    "We will spend more time on the theory of signal processing next time, but I want to introduce two things here:\n",
    "1. Filtering\n",
    "2. Resampling and decimating\n",
    "\n",
    "We saw that there was a lot of low frequency noise in our spectrograms. We can filter that out fairly easily in ObsPy with a highpass/lowcut filter. Remember that:\n",
    "- \"bandpass\" filters retain frequencies *within* a frequency range;\n",
    "- \"lowpass\" filters retain frequencies *below* a frequency;\n",
    "- \"highpass\" filters retain frequencies *above* a frequency;\n",
    "- \"notch\" filters *remove* frequencies within a range (the opposite of bandpass).\n",
    "\n",
    "You can filter data in obspy using the `trace.filter` method - you can find more information on this [here](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.filter.html).\n",
    "\n",
    "Lets try that with our FOZ earthquake data, with a highpass of 2 Hz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"FOZ\", location=\"11\", channel=\"HHZ\",  # Location code changed for FOZ.\n",
    "    starttime=UTCDateTime(2021, 2, 2, 13, 40),\n",
    "    endtime=UTCDateTime(2021, 2, 2, 13, 50))\n",
    "\n",
    "# Filter!\n",
    "st.filter(\"highpass\", freq=2.0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = st.spectrogram(log=True, dbscale=True, axes=ax, show=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we lost the low frequency noise!\n",
    "\n",
    "Try plotting the trace/stream to see this effect in the time-domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try applying a bandpass to some other data of your choosing. Hint: `bandpass` requires two arguments, `freqmin` and `freqmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your filter here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and decimating\n",
    "\n",
    "So far all the GeoNet data that we have looked at have been sampled at 100 Hz.  We can decimate these data to reduce the sampling rate by some factor, or resample (in the frequency domain) to any sampling-rate.  We might want to do this to reduce the computational load for later operations if we do not care about frequencies above some value.  We always have to be concerned about introducing artefacts when doing these operations though: aliasing is a real problem and we will talk about it more next time.\n",
    "\n",
    "For now I want to show you what this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"FOZ\", location=\"11\", channel=\"HHZ\",  # Location code changed for FOZ.\n",
    "    starttime=UTCDateTime(2021, 2, 2, 13, 40),\n",
    "    endtime=UTCDateTime(2021, 2, 2, 13, 50))\n",
    "\n",
    "# Plot the raw data first\n",
    "fig = plt.figure()\n",
    "_ = st.plot(show=False, fig=fig)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimation simply removes samples - it runs the real risk of aliasing, so you should filter first.  We won't here, just to see what decimation does.\n",
    "\n",
    "I will work on a copy of the data to retain the original for later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "decimated = st.copy()\n",
    "decimated.decimate(5)\n",
    "print(decimated)\n",
    "fig = plt.figure()\n",
    "_ = decimated.plot(show=False, fig=fig)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That isn't very nice - we lost the high amplitude spike of the earthquake! This decimation only retains every fifth sample, it so happened that the high amplitude sample wasn't one of those retained... Not the best way to reduce sampling rate?\n",
    "\n",
    "How about resampling in the frequency domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "resampled = st.copy()\n",
    "resampled.resample(20)  # Provide the desired sampling rate\n",
    "print(resampled)\n",
    "fig = plt.figure()\n",
    "_ = resampled.plot(show=False, fig=fig)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks much better - there are more issues here that we will talk about next time, and better ways to resample (using the sinc interpolator!).  That is it for now.\n",
    "\n",
    "Your final exercise is to:\n",
    "1. Download data for stations within 1 degree of GeoNet event [2023p122368](https://www.geonet.org.nz/earthquake/2023p122368), around the event time (use your function)\n",
    "2. Filter the data between 1 and 20 Hz\n",
    "3. Resample the data to a 50 Hz sampling rate\n",
    "4. Plot the data\n",
    "5. Plot the spectrogram\n",
    "6. Compare the frequency content at each station qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
