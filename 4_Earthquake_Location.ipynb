{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake location\n",
    "\n",
    "In this lab we will do some simple earthquake location, using an homogeneous velocity model. We will start with some synthetic data, then move onto adding noise, and finally work with some real arrival times.\n",
    "\n",
    "The point of this lab is not to teach you the maths behind inverse theory (that is saved for MATH323), rather we want you to get a feel for when earthquake locations are well constrained, and when they are less likely to be.\n",
    "\n",
    "Finally you should complete the recommended reading at the bottom of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic theory\n",
    "\n",
    "There are multiple ways to locate an earthquake, and multiple types of earthquake location.  We will mostly\n",
    "consider hypocentre locations here. A light introduction to the theory behind earthquake location can be found in Section 7.2 of Stein and Wysession.\n",
    "\n",
    "The hypocentre of an earthquake is the location that the earthquake starts (in contrast to the centroid location,\n",
    "which is generally the centre of energy release of the earthquake). We can use the phase arrival picks we\n",
    "made when picking last week to constrain the hypocentre. We know from our ray-tracing that, if we know the velocity model, we can work out how long it takes for a ray to travel from the earthquake source to our receiver.  If we have multiple receivers then we can triangulate the location of the earthquake. However, to do that we also need to know the origin time of the earthquake. When we think about solving for an earthquake location we need to remember\n",
    "that we are finding the source in both **space and time**.\n",
    "\n",
    "If we know the time of arrival of the P and S phases we can try and work out the distance from our receiver to\n",
    "the source, but this assumes that the P and S waves follow the same ray-path.  Often the difference is small,\n",
    "but real.\n",
    "\n",
    "The way that we generally locate earthquakes is to invert for the location. There are multiple schemes for how to\n",
    "invert the data: we will just think about simple linearised inversion here, but those taking GPHS446 will see\n",
    "other inversion methods. Linearised inversion works reasonably well for earthquakes that are not close to\n",
    "the surface, are surrounded by receivers, and are within a smooth velocity structure.\n",
    "\n",
    "In a simple homogeneous halfspace the arrival time of a given phase is given by simple trig:\n",
    "\n",
    "\\begin{equation*}\n",
    "    t_i = T + \\frac{\\sqrt{(x - x_i)^2 + (y - y_i)^2 + (z - z_i)^2}}{v}\n",
    "\\end{equation*}\n",
    "\n",
    "where subscript i denotes the $i^{th}$ station, x, y, z are the hypocentre co-ordinates, T is the origin time\n",
    "and v is the wave velocity.\n",
    "\n",
    "<img alt=\"Stein and Wysession Fig 7.2.1\" align=\"centre\" style=\"width:40%\" src=\"http://levee.wustl.edu/seismology/book/chapter7/chap7_sr/7_2_01_s.jpg\">\n",
    "\n",
    "We will use this example of a 2D linear inversion to demonstrate the theory, however there are much better ways to actually locate earthquakes, with more complex and realistic velocity models. There are also many other ways to locate earthquakes, including exhaustive grid searches or less exhaustive grid searches that sample only some of the model space. We can also *relocate* earthquakes by refining their relative locations compared to other events (usually via double-difference methods).\n",
    "\n",
    "## Introduction to inverse theory\n",
    "\n",
    "\\begin{equation*}\n",
    "    d=Fm\n",
    "\\end{equation*}\n",
    "where $d$ is the data (observations), $F$ is some function (a mathematical representation of the physics), and\n",
    "$m$ is the model. In the case of earthquake location, $d$ is our observations of phase arrival times, \n",
    "$m$ is our model of the earthquake location and $F$ is our system of equations linking observations and model.\n",
    "\n",
    "When we locate earthquakes we seek to minimize the error between what our modeled location predicts the arrival\n",
    "times to be, and what we observe the arrival times to be.  We do not have perfect knowledge of the velocity\n",
    "structure of the Earth, nor do we have perfect data (we have noise, so our pick-times will have some uncertainty),\n",
    "so we are unlikely to get a perfect fit between our model and our data. In particular this leads to a system of\n",
    "*inconsistent* equations. Our error is:\n",
    "\n",
    "\\begin{equation*}\n",
    "    e_i = d^{obs}_i - d^{cal}_i\n",
    "\\end{equation*}\n",
    "\n",
    "where $obs$ denotes our observations and $cal$ marks our calculated arrival times. We need to have at least four\n",
    "observations to have a well constrained system of equations (given our four unknowns of X, Y, Z and T). Commonly\n",
    "we will have more than four observations which leads to an *overdetermined* system. To solve an *overdetermined* and *inconsistent* set of equations there is no perfect model, instead we seek the *best* solution. To find the *best* location we seek to minimize:\n",
    "\n",
    "\\begin{equation*}\n",
    "    E = e^Te\n",
    "\\end{equation*}\n",
    "which is the L2 norm. Other choices of norm are available and are made use of by different location methods.\n",
    "\n",
    "To find the best fitting location we can either search through a series of forward-models (where some location\n",
    "and origin time are set and the arrival times calculated), or iteratively search for the best model from\n",
    "some starting model. Here we will consider the iterative method; this is more computationally efficient,\n",
    "but is more susceptible to finding local minima as solutions. In this approach have to make a *guess* at\n",
    "the location and iteratively improve our model.  For local seismicity it is common to use a starting \n",
    "model close to the seismograph with the first arrival at some set depth.\n",
    "\n",
    "To find the *best* solution we compute the partial derivatives of our system and move towards a minima in\n",
    "error. However, in even the homogeneous half-space case, the equations are non-linear: the arrival time \n",
    "depends linearly on distance and origin-time, but not on hypocentral location. The way that we will \n",
    "solve this is to *linearize* the equation by taking the Taylor-series expansion and discarding all \n",
    "higher order terms. \n",
    "\n",
    "When we do this we find that the parital derivatives of the travel time are of the form:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\delta t}{\\delta X} = \\frac{(x - x_i)}{v\\sqrt{(x - x_i)^2 + (y - y_i)^2 + (z - z_i)^2}}\n",
    "\\end{equation*}\n",
    "with similar equations for $y$ and $z$.\n",
    "\n",
    "These partial derivatives tell us the direction towards the next minima: we can compute the unit vector\n",
    "pointing towards the minima as:\n",
    "\\begin{equation*}\n",
    "    \\nu = -\\frac{\\nabla E}{|\\nabla E|}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "I have written a simple, undamped linearised location program in Python in the `geiger_location.py` file.\n",
    "We can call this and give it a go - it will produce plots of the location history.\n",
    "\n",
    "To start with lets start with the perfectly determined case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, some set up!\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# My code uses the \"logging\" module to control output. If you want more output set level=logging.DEBUG\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(name)s\\t%(levelname)s\\t%(message)s\", \n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from gphs445_utilities.location import geiger_locate\n",
    "\n",
    "known_location = {\"x\": 10.0, \"y\": 4.0, \"z\": 12.0, \"time\": 0.0}\n",
    "vp = 5.0\n",
    "vs = 3.0\n",
    "\n",
    "stations = [\n",
    "    {\"x\": 0, \"y\": 0, \"z\": 0},\n",
    "    {\"x\": 2, \"y\": 15, \"z\": 0},\n",
    "    {\"x\": 10, \"y\": 7, \"z\": 0},\n",
    "    {\"x\": 14, \"y\": 12, \"z\": 0}]\n",
    "\n",
    "p_times = np.zeros(len(stations))\n",
    "s_times = np.zeros_like(p_times)\n",
    "\n",
    "for i, station in enumerate(stations):\n",
    "    distance = (\n",
    "        (station[\"x\"] - known_location[\"x\"]) ** 2 +\n",
    "        (station[\"y\"] - known_location[\"y\"]) ** 2 + \n",
    "        (station[\"z\"] - known_location[\"z\"]) ** 2) ** 0.5\n",
    "    p_times[i] = distance / vp\n",
    "    s_times[i] = distance / vs\n",
    "\n",
    "inverted_model = geiger_locate(\n",
    "    p_times=p_times, p_locations=stations, s_times=s_times,\n",
    "    s_locations=stations, vp=vp, vs=vs, starting_depth=5.0, plot=True)\n",
    "\n",
    "print(\"Found a solution at x = {0:.2f}, y = {1:.2f}, z = {2:.2f}, \"\n",
    "      \"time = {3:.2f}\".format(inverted_model[\"x\"], inverted_model[\"y\"],\n",
    "                              inverted_model[\"z\"], inverted_model[\"time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try adding noise to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "p_times = [time + np.random.sample() - .5 for time in p_times]\n",
    "s_times = [time + np.random.sample() - .5 for time in s_times]\n",
    "\n",
    "inverted_model = geiger_locate(\n",
    "    p_times=p_times, p_locations=stations, s_times=s_times,\n",
    "    s_locations=stations, vp=vp, vs=vs, starting_depth=5.0, plot=True)\n",
    "\n",
    "print(\"Solution at x = {0:.2f}, y = {1:.2f}, z = {2:.2f}, \"\n",
    "      \"time = {3:.2f}\".format(inverted_model[\"x\"], inverted_model[\"y\"],\n",
    "                              inverted_model[\"z\"], inverted_model[\"time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't get perfectly back to our initial location when we add noise in the range (-0.5, 0.5), unsurprisngly.\n",
    "\n",
    "How about making it overdetermined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "stations = [\n",
    "    {\"x\": 0, \"y\": 0, \"z\": 0},\n",
    "    {\"x\": 2, \"y\": 15, \"z\": 0},\n",
    "    {\"x\": 10, \"y\": 7, \"z\": 0},\n",
    "    {\"x\": 14, \"y\": 12, \"z\": 0},\n",
    "    {\"x\": 20, \"y\": 2, \"z\": 1.2},\n",
    "    {\"x\": 16, \"y\": 20, \"z\": -0.5},\n",
    "    {\"x\": -20, \"y\": -12, \"z\": 0},\n",
    "    {\"x\": -14, \"y\": -6, \"z\": 0},\n",
    "    {\"x\": 30, \"y\": -10, \"z\": 0},\n",
    "    {\"x\": -25, \"y\": 20, \"z\": 0}]\n",
    "\n",
    "p_times = np.zeros(len(stations))\n",
    "s_times = np.zeros_like(p_times)\n",
    "\n",
    "for i, station in enumerate(stations):\n",
    "    distance = (\n",
    "        (station[\"x\"] - known_location[\"x\"]) ** 2 +\n",
    "        (station[\"y\"] - known_location[\"y\"]) ** 2 + \n",
    "        (station[\"z\"] - known_location[\"z\"]) ** 2) ** 0.5\n",
    "    p_times[i] = distance / vp\n",
    "    s_times[i] = distance / vs\n",
    "\n",
    "p_times = [time + np.random.sample() - .5 for time in p_times]\n",
    "s_times = [time + np.random.sample() - .5 for time in s_times]\n",
    "    \n",
    "inverted_model = geiger_locate(\n",
    "    p_times=p_times, p_locations=stations, s_times=s_times,\n",
    "    s_locations=stations, vp=vp, vs=vs, convergence=0.00001, \n",
    "    starting_depth=5.0, plot=True)\n",
    "\n",
    "print(\"Found a solution at x = {0:.2f}, y = {1:.2f}, z = {2:.2f}, \"\n",
    "      \"time = {3:.2f}\".format(inverted_model[\"x\"], inverted_model[\"y\"],\n",
    "                              inverted_model[\"z\"], inverted_model[\"time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't get a much better location, but we are able to get close, despite the noise.\n",
    "\n",
    "\n",
    "Now it is your turn. Try the following with noise and without:\n",
    "\n",
    "1. Try starting the location at a depth of 100km for a simulated earthquake at 10 km depth - does the inversion converge?\n",
    "2. Try to locate an earthquake at 5 km depth, 10 km outside your set of stations, e.g. all the stations should be on one side of the earthquake - how well resolved is the final location and why?\n",
    "3. Try to locate an earthquake that is shallower than half the distance to the nearest station - how well resolved is the final location and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try a real earthquake from GeoNet and see how well the simple model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "from gphs445_utilities.location import geiger_locate_lat_lon\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "client = Client(\"GEONET\")\n",
    "event = client.get_events(eventid=\"2019p345502\")[0]\n",
    "bulk = [\n",
    "    (pick.waveform_id.network_code, pick.waveform_id.station_code,\n",
    "     pick.waveform_id.location_code, pick.waveform_id.channel_code, \n",
    "     pick.time - 300, pick.time + 300) for pick in event.picks]\n",
    "inventory = client.get_stations_bulk(bulk, level=\"channel\")\n",
    "\n",
    "p_times, p_locations, s_times, s_locations = ([], [], [], [])\n",
    "\n",
    "for pick in event.picks:\n",
    "    try:\n",
    "        loc = inventory.get_coordinates(pick.waveform_id.get_seed_string())\n",
    "    except:\n",
    "        print(\"No location found for {0}\".format(\n",
    "            pick.waveform_id.get_seed_string()))\n",
    "        continue\n",
    "    if pick.phase_hint == \"P\":\n",
    "        p_times.append(pick.time)\n",
    "        p_locations.append(\n",
    "            {\"lat\": loc[\"latitude\"], \"lon\": loc[\"longitude\"], \n",
    "             \"z\": loc[\"elevation\"] / 1000.})\n",
    "    elif pick.phase_hint == \"S\":\n",
    "        s_times.append(pick.time)\n",
    "        s_locations.append(\n",
    "            {\"lat\": loc[\"latitude\"], \"lon\": loc[\"longitude\"], \n",
    "             \"z\": loc[\"elevation\"] / 1000.})\n",
    "\n",
    "print(f\"We have {len(s_times)} S picks and {len(p_times)} P picks.\")\n",
    "\n",
    "model = geiger_locate_lat_lon(p_times, p_locations, s_times, s_locations, vp=5.8,\n",
    "                              vs=3.36, plot=True, starting_depth=5.)\n",
    "\n",
    "print(\"GeoNet location: {0:.2f} latitude, {1:.2f} longitude, {2:.2f} depth (km) {3} origin time\".format(\n",
    "    event.preferred_origin().latitude, event.preferred_origin().longitude,\n",
    "    event.preferred_origin().depth / 1000., event.preferred_origin().time))\n",
    "print(\"Homogeneous model location: {0:.2f} latitude, {1:.2f} longitude, {2:.2f} depth (km) {3} origin time\".format(\n",
    "    model[\"lat\"], model[\"lon\"], model[\"z\"], model[\"time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The homogeneous location is epicentrally close to GeoNet location, but 10 km deeper! It turns out that the GeoNet event was located using a linearised inversion, without weights, and in the IASP91 velocity model. The IASP91 velocity model looks like this:\n",
    "\n",
    "<img alt=\"IASP91 global 1D velocity model\" align=\"centre\" style=\"width:40%\" src=\"http://ds.iris.edu/spudservice/data/9991806?nolog=y\">\n",
    "\n",
    "For the upper 20 km the P-wave velocity in IASP91 is 5.8 km/s and S-wave velocity is 3.36 km/s, as we have used above. So why the difference in depths? On closer inspection of the SeisComp files it looks like a mistake in the S travel-time tables for shallow earthquakes (if you want to look at these travel-time tables see [here](https://github.com/SeisComP/common/blob/master/libs/3rd-party/locsat/data/iasp91.S) where there is a negative travel-time for 0km depth S-arrivals).  \n",
    "\n",
    "In this fairly unusual situation (good azimuthal coverage in P and S arrivals, and a reasonable number of nearby stations) we can simulate this error by subtracting time from our S-pick times - I found about 2.4 s works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "s_times_fudged = [s_time - 2.4 for s_time in s_times]\n",
    "\n",
    "model_fudged = geiger_locate_lat_lon(p_times, p_locations, s_times_fudged, s_locations, vp=5.8,\n",
    "                                     vs=3.36, plot=True, starting_depth=5.)\n",
    "\n",
    "print(\"Homogeneous model (fudged) location: {0:.2f} latitude, {1:.2f} longitude, {2:.2f} depth (km) {3} origin time\".format(\n",
    "    model_fudged[\"lat\"], model_fudged[\"lon\"], model_fudged[\"z\"], model_fudged[\"time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I locate this earthquake in the iasp91 velocity model in a different program (*hypocentre*) I end up with a location somewhere in the middle at 13.8 km depth, closer to mine than GeoNet. The main difference between my location and the *hypocentre* derived location is that *hypocentre* incorporates refracted arrivals - for more distant stations the PN arrival ends up being first.\n",
    "\n",
    "Lets have a play with this and look at the trade-off between depth and origin time for one station by calculating the expected first arrival for one station with varying depths. We can use ObsPy's intergration of the TauP program to calculate travel-times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy.taup import TauPyModel\n",
    "from obspy.geodetics import gps2dist_azimuth, kilometers2degrees\n",
    "\n",
    "iasp_model = TauPyModel(\"iasp91\")\n",
    "\n",
    "def get_traveltime(lat, lon, depth, station_lat, station_lon):  \n",
    "    dist, _, _ = gps2dist_azimuth(station_lat, station_lon, lat, lon)\n",
    "    dist /= 1000.0\n",
    "    dist = kilometers2degrees(dist)\n",
    "    arrivals = iasp_model.get_travel_times(\n",
    "            source_depth_in_km=depth, distance_in_degree=dist)\n",
    "    return arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "station_name = \"EAZ\"\n",
    "\n",
    "lat, lon = -44.27, 169.36\n",
    "depths = np.arange(0, 50, 0.5)\n",
    "\n",
    "station = inventory.select(station=station_name)[0][0]\n",
    "\n",
    "direct_p, moho_p = [], []\n",
    "\n",
    "for depth in depths:\n",
    "    arrivals = get_traveltime(lat, lon, depth, station.latitude, station.longitude)\n",
    "    _direct = [arr for arr in arrivals if arr.name == \"p\"]\n",
    "    _moho = [arr for arr in arrivals if arr.name == \"Pn\"]\n",
    "    if len(_direct) == 0:\n",
    "        direct_p.append(np.nan)\n",
    "    else:\n",
    "        direct_p.append(_direct[0].time)\n",
    "    if len(_moho) == 0:\n",
    "        moho_p.append(np.nan)\n",
    "    else:\n",
    "        moho_p.append(_moho[0].time)\n",
    "        \n",
    "        \n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(depths, direct_p, label=\"Direct\")\n",
    "ax.scatter(depths, moho_p, label=\"Refracted\")\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try playing around with different stations - what do you think these sharp velocity boundaries do to the inversion process?\n",
    "\n",
    "We can also look at the range of phases that we would expect below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "station_lat, station_lon = station.latitude, station.longitude\n",
    "dist, _, _ = gps2dist_azimuth(station_lat, station_lon, lat, lon)\n",
    "dist /= 1000.0\n",
    "dist = kilometers2degrees(dist)\n",
    "\n",
    "arrivals = iasp_model.get_ray_paths(\n",
    "    source_depth_in_km=200, distance_in_degree=dist, phase_list=[\"ttbasic\"])\n",
    "\n",
    "ax = arrivals.plot_rays(plot_type=\"cartesian\", plot_all=False, label_arrivals=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
