{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnitudes and focal mechanisms\n",
    "\n",
    "This notebook covers three simple objectives:\n",
    "1. Demonstrate instrument response removal and instrument simulation\n",
    "2. Comparison of magnitude types\n",
    "3. Simple focal mechanism fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing instrument response\n",
    "\n",
    "You know that we can describe the effect of a seismograph's recording system as a series of linear filters. Thusfar we have worked solely with data in raw counts, as recorded by the seismograph, however, we often want to get real ground-motion amplitudes from our data. To do that we can remove the instrument response by deconvolving it from our recorded data.  We will use Obspy to correct for that instrument response and convert from *counts* to some physical unit in acceleration, velocity or displacement.\n",
    "\n",
    "Lets look at what a broadband instrument ([JCZ](https://www.geonet.org.nz/data/network/sensor/JCZ)) looks like after Kaikoura in counts, displacement, velocity and acceleration.\n",
    "\n",
    "First we will download the data and response information for that site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "\n",
    "client = Client(\"GEONET\")\n",
    "st = client.get_waveforms(\n",
    "    network=\"NZ\", station=\"JCZ\", channel=\"HHZ\", location=\"10\",\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11, 2),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 10))\n",
    "inv = client.get_stations(\n",
    "    network=\"NZ\", station=\"JCZ\", channel=\"HHZ\", location=\"10\",\n",
    "    starttime=UTCDateTime(2016, 11, 13, 11, 2),\n",
    "    endtime=UTCDateTime(2016, 11, 13, 11, 10),\n",
    "    level=\"response\")  # We need to set level=response to get the response info.\n",
    "\n",
    "fig = st.plot(show=False, handle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are going to be working in the frequency domain, which assumes that our signals are periodic, we will first detrend and taper our data. **Don't forget to detrend!** You don't always need to taper, but you (almost) always need to detrend..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st = st.detrend().taper(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the stream from counts to ground motion using the `.remove_response()` method and specifying the `output` argument.  See the [remove_response docs](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.remove_response.html) for more options.  `remove_response` works in place on the data, so we will copy the stream first to ensure we can still access the original data.\n",
    "\n",
    "First we can convert to and plot displacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "st_disp = st.copy().remove_response(inventory=inv, output=\"DISP\")\n",
    "\n",
    "fig = st_disp.plot(handle=True)\n",
    "ax = fig.gca()\n",
    "_ = ax.set_ylabel(\"Displacement (m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can convert to velocity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "st_vel = st.copy().remove_response(inventory=inv, output=\"VEL\")\n",
    "\n",
    "fig = st_vel.plot(handle=True)\n",
    "ax = fig.gca()\n",
    "_ = ax.set_ylabel(\"Velocity (m/s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And acceleration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "st_acc = st.copy().remove_response(inventory=inv, output=\"ACC\")\n",
    "\n",
    "fig = st_acc.plot(handle=True)\n",
    "ax = fig.gca()\n",
    "_ = ax.set_ylabel(\"Acceleration ($m/s^2$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the steps being taken during the instrument correction process Obspy's plot option when removing response can be instructive. Lets have a look at what is happening here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "st.copy().remove_response(inventory=inv, output=\"VEL\", plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is showing us the main steps taken when removing the instrument response in the frequency domain (left) and time-domain. These steps are:\n",
    "1. Pre-filter (we have selected none for this option),\n",
    "2. Deconvolve instrument response (red line in frequency plot, row 2) - remember that deconvolution is division in the frequency domain - (although in ObsPy this is actually done as multiplication with one-over the instrument response.\n",
    "3. Apply water-level.\n",
    "\n",
    "Steps 1 and 3 are done to stabilise the process. The pre-filter can be used to make sure that unrealistic frequencies are not included. The water-level can be used to remove frequencies that have been over-gained in the division process due to numerical instabilities (remember that $\\frac{x}{0} = \\infty$, and that numbers close to zero may be mis-represented as zero due to numerical precision).\n",
    "\n",
    "## Exercise:\n",
    "\n",
    "Try downloading a strong-motion (channel codes starting with HN) and a short-period (channel codes starting with EH) site for Kaikoura and convert both of those to velocity as above with the plot on - how different do the instrument response and corrected data look?\n",
    "\n",
    "For stations, try \n",
    "- WNPS, location=20, channels=HNZ (Wanaka)\n",
    "- GCSZ, location=10, channels=EHZ (Gaunt Creek, DFDP 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Magnitudes\n",
    "\n",
    "We commonly describe an earthquakes size based on its magnitude. There are various magnitude scales in use, but all vary logarithmically. In a general sense, the energy released by a magnitude 2 earthquake is roughly ten times greater than a magnitude 1, but this varies with stress drop and shear modulus: energy is not simply related to magnitude... However, most magnitude scales are not related to energy even indirectly, only the moment magnitude ($M_W$) scale is tied indirectly to energy release.\n",
    "\n",
    "In this notebook we will look at how the following magnitudes are calculated:\n",
    "- Local Magnitude ($M_L$);\n",
    "- Coda-duration Magnitude ($M_D$).\n",
    "\n",
    "The theory behind most of this can be found in Section 4.6 of Stein and Wysession.  We are not going to cover moment magnitude calculation because this requires some additional knowledge of source process, however, for some information on a recent development in computing moment magnitudes, check out the W-phase moment magnitude method (which is now routinely in use by USGS for fast determination of large earthquake magnitudes), and the paper by [Duputel et al., 2012](https://academic.oup.com/gji/article/189/2/1125/621962).\n",
    "\n",
    "For a list of other commonly used scales, see the [USGS table of magnitudes.](https://www.usgs.gov/programs/earthquake-hazards/magnitude-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Magnitude\n",
    "\n",
    "$M_L$ began life as the *Richter magnitude*, however, this is a magnitude scale with specific scaling parameters for Southern California. The same equation form used in the initial Richter scale is used elsewhere, but with appropriate attenuation parameters: if the original Southern California Richter scale is used in New Zealand it doesn't give the correct result (as well will see when we try to use it!).\n",
    "\n",
    "$M_L$ is based on the measurement of the peak amplitude in a waveform recorded by a *Wood-Anderson* seismometer. There are very few Wood-Anderson seismometers still in operation today, but we know what the instrument response of a Wood-Anderson instrument is, and can therefore simulate Wood-Anderson waveforms from other instruments by correcting for the original instruments response (as above) and convolving the resulting ground motion with the response of a Wood-Anderson instrument.  \n",
    "\n",
    "The original Richter local magnitude scale is:\n",
    "\n",
    "\\begin{equation*}\n",
    "    M_L = \\log{A} + 2.76\\log{\\Delta} - 2.48\n",
    "\\end{equation*}\n",
    "where $A$ is the peak amplitude (in micro-meters) on a Wood-Anderson seismometer, $\\Delta$ is the epicentral distance. This only works well for shallow earthquakes. The second term effectively corrects for geometrical spreading, while the final factor is included to scale the magnitude.\n",
    "\n",
    "The adapted local magnitude scale for New Zealand is:\n",
    "\\begin{equation*}\n",
    "    M_L = \\log{A} + \\log{\\Delta} + 0.0029\\Delta + S\n",
    "\\end{equation*}\n",
    "where S is a station correction term. See [Ristau, 2009](https://pubs.geoscienceworld.org/ssa/bssa/article/99/3/1841/342119/comparison-of-magnitude-estimates-for-new-zealand) for a discussion of some of the magnitudes in use in New Zealand.\n",
    "\n",
    "Recent work by [Michailos et al., 2019](https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018GC007743) derived a robust local magnitude scale for the Southern Alps tied to moment magnitude:\n",
    "\n",
    "\\begin{equation*}\n",
    "    M_L = \\log{A} + \\log{r} + \\eta r - S - 3.644\n",
    "\\end{equation*}\n",
    "where $r$ is the hypocentral distance, $\\eta$ is an attenuation parameter, which, for $r\\le 60km$ is $1.2\\times 10^{-2}km^{-1}$ and for $r>60km$ is $0.01\\times 10^{-2}km{-1}$. $S$ is a site dependent correction which incorporates local site effects. Geometrical spreading is assumed to be logarithmically related to $r$, with a gradient of 1.\n",
    "\n",
    "The reason that we end up with multiple magnitude scales is similar to the reason we need to include station correction terms: we don't do a good job of correcting for path effects. When the paths change, the geology the waves encounter is different and so the attenuation is different. Although we correct for some of the attenuation in the attenuation correction terms, these don't capture the 3D range of variability we see in the geology.  This is also part of the reason why we get different magnitude estimates from different stations (another major factor is that amplitudes vary with azimuth from the source, as well as directivity affects).\n",
    "\n",
    "Lets look at how we would pick an amplitude for local magnitude for a nearby earthquake. We will use the `seismic_picker.py` applet again which has been extended to allow amplitude and duration picks to be made.\n",
    "\n",
    "**TO MAKE THIS WORK YOU WILL NEED TO RESTART YOUR KERNEL (press the recycle button at the top of the screen) TO ALLOW POP UP WINDOWS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "from obspy.clients.fdsn import Client\n",
    "from gphs445_utilities.plot_event import get_geonet_waveforms\n",
    "\n",
    "client = Client(\"GEONET\")\n",
    "event = client.get_events(eventid=\"2019p304574\")[0]\n",
    "# Lets just use the five closest weak motion stations\n",
    "clean_event = event.copy()\n",
    "clean_event.picks = [\n",
    "    p for p in sorted(event.picks, key=lambda p: p.time) \n",
    "    if p.waveform_id.channel_code[0] != \"B\"][0:5]\n",
    "\n",
    "# We want to remove the amplitudes already picked, and magnitudes so that we can overwrite them with our own.\n",
    "clean_event.amplitudes = []\n",
    "clean_event.station_magnitudes = []\n",
    "\n",
    "st = get_geonet_waveforms(clean_event, all_components=True)\n",
    "st = st.detrend().taper(0.05)\n",
    "#st.plot()  # For some reason on Windows I need to plot in this first cell to get later plots to work.\n",
    "# We need to response information for the stations so that we can correct\n",
    "# the repsonse and simulate a wood anderson instrument.\n",
    "bulk = [\n",
    "    (p.waveform_id.network_code, p.waveform_id.station_code, \n",
    "     p.waveform_id.location_code, p.waveform_id.channel_code[0:-1] + \"?\", \n",
    "     p.time - 60, p.time + 200) for p in clean_event.picks]\n",
    "inv = client.get_stations_bulk(bulk, level=\"response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pick local magnitudes we want to simulate a Wood-Anderson instrument.  To do this we can use obspy's \n",
    "[remove_response](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.remove_response.html#obspy.core.stream.Stream.remove_response)\n",
    "and [simulate](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.simulate.html#obspy.core.stream.Stream.simulate) \n",
    "methods to remove the instrument response then apply the Wood-Anderson response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paz_WA = {'poles': [-6.283 + 4.7124j, -6.283 - 4.7124j],\n",
    "          'zeros': [0 + 0j], 'gain': 1.0, 'sensitivity': 2080}\n",
    "st_wa = st.copy()\n",
    "st_wa = st_wa.remove_response(inv, \"DISP\")\n",
    "st_wa = st_wa.simulate(paz_remove=None, paz_simulate=paz_WA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the picker. Amplitude picks for local magnitudes were originally defined as being picked on the\n",
    "horizontals, however vertical channels are sometimes used because they are less succeptible to shallow amplification effects. Picks should be made at the maximum amplitude.  The picker will record your mouse position and add an `Amplitude` and a `Pick` for that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from gphs445_utilities.seismic_picker import SeismicPicker\n",
    "\n",
    "picker = SeismicPicker(st_wa, event_in=clean_event)\n",
    "event_out = SeismicPicker(st_wa, event_in=clean_event).pick()\n",
    "print(event_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "event_picked = event_out.copy()\n",
    "# Quick plot to check that the picks are recorded in the right place\n",
    "SeismicPicker(st_wa, event_picked).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "for amplitude in event_picked.amplitudes:\n",
    "    if amplitude.type != \"END\":\n",
    "        print(\"Amplitude: {0:.2g} m\".format(amplitude.generic_amplitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know where the earthquake was to calculate the hypocentral distance. We will use the `coordinates.py` classes to\n",
    "estimate distance (using a flat earth approximation, so only good for local earthquakes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "from gphs445_utilities.location import Geographic\n",
    "from math import log10\n",
    "\n",
    "def _distance(point_1, point_2):\n",
    "    \"\"\"\n",
    "    Calcuate hypocentral distance from Geographic points\n",
    "    \n",
    "    :type point_1: `coordinates.Geographic`\n",
    "    :type point_2: `coordinates.Geographic`\n",
    "    \n",
    "    :returns: float\n",
    "    \"\"\"\n",
    "    point_2_xyz = point_2.to_xyz(origin=point_1, strike=0, dip=90)\n",
    "    return (point_2_xyz.x ** 2 + point_2_xyz.y ** 2 + point_2_xyz.z ** 2) ** 0.5\n",
    "\n",
    "origin = clean_event.preferred_origin()\n",
    "origin = Geographic(\n",
    "    latitude=origin.latitude, longitude=origin.longitude, \n",
    "    depth=origin.depth / 1000.)\n",
    "magnitude = 0\n",
    "used_station_count = 0\n",
    "for amplitude in event_picked.amplitudes:\n",
    "    if amplitude.type == 'END':\n",
    "        continue\n",
    "    pick = amplitude.pick_id.get_referred_object()\n",
    "    station_loc = inv.get_coordinates(pick.waveform_id.get_seed_string(),\n",
    "                                      pick.time)\n",
    "    station_loc = Geographic(\n",
    "        latitude=station_loc[\"latitude\"], longitude=station_loc[\"longitude\"],\n",
    "        depth=(station_loc[\"local_depth\"] - station_loc[\"elevation\"]) / 1000.)\n",
    "    distance = _distance(origin, station_loc)\n",
    "    print(\"Amplitude {0:.2g} m at {1:.2f} km\".format(\n",
    "        amplitude.generic_amplitude, distance))\n",
    "    station_magnitude = (\n",
    "        log10(abs(amplitude.generic_amplitude) * 1e6) + log10(distance) - \n",
    "        0.0029 * distance + 0)\n",
    "    print(\"Using the Richter scale gives: {0:.2f}\".format(station_magnitude))\n",
    "    magnitude += station_magnitude\n",
    "    used_station_count += 1\n",
    "\n",
    "if used_station_count == 0:\n",
    "    print(f\"No amplitude picks found\")\n",
    "else:\n",
    "    magnitude /= used_station_count\n",
    "    print(\"Average magnitude: {0:.2f}\".format(magnitude))\n",
    "    print(\"GeoNet magnitude: {0:.2f}\".format(clean_event.preferred_magnitude().mag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magnitude I calculated is a little high, this is likely because we used attenuation parameters that are\n",
    "not appropriate for the region of the Earthquake, and we have not included any station correction terms.\n",
    "Another factor may be incorrect amplitude picks: it is common to pick amplitudes as half the peak-to-trough \n",
    "amplitudes to remove any bias due to dc-shifts in the data, but I haven't incorporated that into the picker yet.\n",
    "\n",
    "Note that GeoNet report an *average* magnitude, based on multiple different magnitude estimates.  The local\n",
    "magnitudes currently calculated by GeoNet are also slightly different in that they calculate $M_{Lv}$ magnitudes,\n",
    "which do not correct to displacement waveforms, so the magnitude that they calculate is somewhat different to\n",
    "the equation used above.  The main reason for computing $M_{Lv}$ is to avoid possible instabilities in the integration from velocity\n",
    "seismograms to displacement.\n",
    "\n",
    "## Exercise:\n",
    "\n",
    "Repeat the above for a small magnitude (~M 2) earthquake somewhere in New Zealand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coda-duration Magnitude\n",
    "\n",
    "Coda-duration magnitude is a simple and fast way of estimating local event magnitude, however this is not in use in New Zealand. Japan, California, Mexico, Italy and other places all have coda magnitude calculations, so we will select one of these magnitude-scales to compute coda-duration magnitudes.  The principle is to measure the time between the initial P-wave and the time that the seismogram drops below some noise threshold. How this is defined is different from place-to-place, and coda magnitudes are usually scaled to some other magnitude. See Page 70 of the [NMSOP, Chapter 3](http://gfzpublic.gfz-potsdam.de/pubman/item/escidoc:108170:12/component/escidoc:364681/Chapter_3.pdf).\n",
    "\n",
    "We will use the Mexican scale:\n",
    "\\begin{equation*}\n",
    "    M_d = 2.40\\log{d} + 0.00046\\Delta - 1.59\n",
    "\\end{equation*}\n",
    "where d is the duration in seconds.\n",
    "\n",
    "Similar to amplitudes, shaking duration is strongly dependent on local geology and near-site amplification effects, so duration magnitude scales should be tuned for the region (and instrument!) in question.\n",
    "\n",
    "You can add duration picks to channels with P-phase picks in the picker using the \"e\" key. Try to pick when the amplitudes drop back to roughly the pre-event noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "event_picked = SeismicPicker(st_wa, event_picked).pick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "magnitude = 0\n",
    "used_station_count = 0\n",
    "for amplitude in event_picked.amplitudes:\n",
    "    if amplitude.type != 'END':\n",
    "        continue\n",
    "    pick = amplitude.pick_id.get_referred_object()\n",
    "    station_loc = inv.get_coordinates(pick.waveform_id.get_seed_string(),\n",
    "                                      pick.time)\n",
    "    station_loc = Geographic(\n",
    "        latitude=station_loc[\"latitude\"], longitude=station_loc[\"longitude\"],\n",
    "        depth=(station_loc[\"local_depth\"] - station_loc[\"elevation\"]) / 1000.)\n",
    "    distance = _distance(origin, station_loc)\n",
    "    print(\"Duration {0:.2g} s at {1:.2f} km\".format(\n",
    "        amplitude.generic_amplitude, distance))\n",
    "    station_magnitude = (\n",
    "        2.4 * log10(amplitude.generic_amplitude) + 0.00046 * distance - 1.59)\n",
    "    print(\"Using the Mexican Md scale gives: {0}\".format(station_magnitude))\n",
    "    magnitude += station_magnitude\n",
    "    used_station_count += 1\n",
    "\n",
    "if used_station_count == 0:\n",
    "    print(\"No duration picks found\")\n",
    "else:\n",
    "    magnitude /= used_station_count\n",
    "    print(\"Average magnitude: {0}\".format(magnitude))\n",
    "    print(\"GeoNet magnitude: {0}\".format(clean_event.preferred_magnitude().mag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I do this my magnitude is clearly too low, which suggests that the coda duration is poorly picked, or/and that the Mexican magnitude scale is not appropriate for New Zealand. \n",
    "\n",
    "Hopefully you can see that the measurements for both amplitude and duration based magnitude scales could fairly easily be automated, and this is generally the case. Both maximum amplitude and duration are fairly simple to code, but both can be prone to issues with overlapping events. As ever, manual intervention and checking is very useful, so knowing what to look for is key!\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Pick coda-duration magnitude for your chosen small earthquake from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Focal Mechanisms and Moment Tensors\n",
    "\n",
    "Focal mechanisms describe slip on a fault arising from a purely double couple source. See Stein and Wysession's Section 4.4 for a discussion of force couples and single forces. Focal mechanisms inherently have ambiguity over which of the two resolved planes is the actual fault plane, and in general additional evidence is required to determine which plane is the fault plane. Focal mechanisms are commonly used to describe the faulting styles in a region, and to invert for principle stress axes orientations. \n",
    "\n",
    "Understanding stress orientations (and magnitude, which cannot be derived from focal mechanism inversion) is becoming useful for understanding the likelihood of induced earthquakes (e.g.: \n",
    "[Lund Snee and Zoback 2018](https://pubs.geoscienceworld.org/tle/article/37/2/127/527282/state-of-stress-in-the-permian-basin-texas-and-new)) and for understanding how stresses change around slow-slip events (e.g. [Warren-Smith et al., 2019](https://www.nature.com/articles/s41561-019-0367-x)) amongst other applications.\n",
    "\n",
    "## First motions\n",
    "\n",
    "The simplest and most widely used method for estimating focal mechanisms is to use the first-motion polarities of P-waves to determine which quadrant of the focal sphere a station lies in. The `seismic_picker.py` applet has been extended to allow you to pick polarities. Note that this needs to be the first motion polarity, **not** the polarity of the maximum peak. The wavetrain of an individual seismic phase is a superposition of different ray-paths, which may be of opposite polarities.  Polarities are either compressional (up) or dilatational (down). Waves that show compressive first motions arise when the faults first motion is towards the seismometer (along the ray-path, which may take an *interesting* path to the seismometer). Dilatational waves arise when the faults first motion is away from the seismometer.\n",
    "\n",
    "<img alt=\"Stein and Wysession Fig 4.2-4\" align=\"centre\" style=\"width:40%\" src=\"http://levee.wustl.edu/seismology/book/chapter4/chap4_sr/4_2_04_s.jpg\">\n",
    "\n",
    "Once polarities are measured they can be plotted on a stereonet with the position based on the take-off angle and back azimuth of the ray between the source and the receiver to obtain a scatter of points on the focal sphere. These points can be inverted to obtain a best fitting focal mechanism. Some important things to note are:\n",
    "1. First motion amplitudes tend to zero towards the nodal planes thus polarities may be obscured close to nodal planes and be impossible to reliably pick;\n",
    "2. Polarities are plotted based on take-off angle and azimuth. Both properties require accurate hypocentre locations and accurate ray-tracing;\n",
    "3. Lower-hemisphere stereonets are commonly used because take-off angles for first arriving rays are often downwards (towards a faster medium).\n",
    "   \n",
    "To construct a focal mechanism we need polarity readings, as well as back azimuths and takeoff angles of rays. Sadly it doesn't look like GeoNet shares the takeoff angles for their events, so we are going to work with a catalogue of events that I re-located in NonLinLoc using the NZ wide 3D velocity model from [Eberhart-Phillips et al.](https://zenodo.org/record/3779523#.YGT_KBLRVhE)\n",
    "\n",
    "You will pick polarities of an event in this catalogue, then try to fit a focal mechanism to those polarities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from gphs445_utilities.seismic_picker import SeismicPicker\n",
    "from gphs445_utilities.plot_event import get_geonet_waveforms\n",
    "\n",
    "from obspy import read_events\n",
    "\n",
    "cat = read_events(\"NLL_located.xml\")  # You need to point this towards the file you download from Blackboard.\n",
    "\n",
    "event = cat[0]\n",
    "print(\"Event has {0} picks\".format(len(event.picks)))\n",
    "# We will remove the picks from strong motion sites, I don't know whether they are all wired the same way\n",
    "event.picks = [p for p in event.picks \n",
    "               if p.waveform_id.location_code != \"20\"]\n",
    "\n",
    "# Lets just look at the first 20 P-picks - we need to remove duplicate picks to do this.\n",
    "event.picks.sort(key=lambda p: p.time)\n",
    "_picks, stations = [], []\n",
    "for p in event.picks:\n",
    "    if len(_picks) == 20:\n",
    "        break\n",
    "    elif p.phase_hint == \"P\" and p.waveform_id.station_code not in stations:\n",
    "        # We need to check that this station has a real arrival computed\n",
    "        arr = [a for a in (event.preferred_origin() or event.origins[0]).arrivals \n",
    "               if a.pick_id.get_referred_object() == p]\n",
    "        if len(arr) == 0:\n",
    "            continue\n",
    "        if arr[0].distance == 0:\n",
    "            continue\n",
    "        _picks.append(p)\n",
    "        stations.append(p.waveform_id.station_code)\n",
    "event.picks = _picks\n",
    "\n",
    "st = get_geonet_waveforms(event=event, all_components=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some data, lets pick the polarities. A key thing to remember is: *if you can't reliably pick the polarity, then do not pick the polarity!*.\n",
    "\n",
    "You will probably have to zoom in around the P-pick to see the polarity - remember that we are looking for the polarity of the first arriving wave - this may be quite a small bump!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "# We will add polarities to this GeoNet event.\n",
    "picked_event = SeismicPicker(st.select(component=\"Z\"), event_in=event).pick()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have polarities, we can use the take-off angles and azimuth that I calculated to plot our polarities on the focal sphere. Note that `event.origins[n].arrivals` contains the takeoff angle and azimuth information we need.\n",
    "\n",
    "We are going to use a simple focal-mechanism viewer that I coded that will allow us to find a set of nodal planes that fit our data. In practice we would usually invert for these planes, but for teaching purposes I find it instructive to get you to try and fit them yourself. The inversion process is a simple grid-search method, where you test how well various sets of nodal planes fit your data and select the best fitting set. There are lots of methods for doing this, and for obtaining uncertainties. One interesting one is [MTFit](https://djpugh.github.io/MTfit/index.html) which computes the best fit moment tensor based on Bayesian statistics, and allows for amplitude ratios to be included.  Finn Ilsley-Kemp has been using this recently to good effect when looking at [volcanic earthquakes](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021GC009803)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try and plot this and fit the planes ourselves. to adjust the planes, move the sliders at the bottom of the following plot. Things to remember when fitting these planes:\n",
    "1. Planes should separate positive and negative polarities!\n",
    "2. I find it easier to get one plane close to where I think it should be, then fry and fit the second.\n",
    "3. The sign of the rake (positive or negative) must be the same for both nodal planes.\n",
    "4. I find it easier to get somewhere near in strike, then adjust the dip and strike together so that the second nodal plane intersects the pole to the first nodal plane, then adjust the rake last.\n",
    "\n",
    "The planes **must be orthogonal to one-another**: orthogonal planes are constrained such that the slip-vector of one-plane is the normal to the other. In this plot that means that the pole to nodal-plane 1 must align with the rake of nodal-plane 2 (and vice-versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from gphs445_utilities.focal_mechanisms import FocalMechanism\n",
    "\n",
    "fm = FocalMechanism.from_event(picked_event)\n",
    "with warnings.catch_warnings():\n",
    "    # the stereonet transform raises some warnings that we don't need to worry about\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fm.find_planes(show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down your best fitting nodal planes, then try another event (change the index in the brackets - there are only about 20 events in this catalogue, and some of them don't have many arrivals, so you might not be able to make focal mechanisms for them all!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Stein and Wysession Fig 4.2-7\" align=\"right\" style=\"width:50%\" src=\"http://levee.wustl.edu/seismology/book/chapter4/chap4_sr/4_2_07_s.jpg\">\n",
    "\n",
    "## Amplitude ratios\n",
    "\n",
    "A simple extension of the first motion method is to take advantage of the difference in P and S-wave radiation patterns (see figure).\n",
    "\n",
    "By taking the ratio of P and S wave amplitudes we can estimate where on the focal sphere we are. This provides additional information\n",
    "to better constrain the focal mechanism, and can be especially useful near the nodal planes, where S amplitude is maximized but first\n",
    "motion polarities of P waves can be hard to pick. We won't make use of this in your assignment, but you should read Stein and Wysession 4.2.3.\n",
    "\n",
    "Focal mechanisms can also be estimated by modelling body or/and surface waves, see Stein and Wysession 4.3.\n",
    "\n",
    "## Moment tensor inversion\n",
    "\n",
    "So far we have just considered the information relating to simple slip on a single fault, however, natural events are often more complicated. At relatively low sampling\n",
    "frequencies and large station-reciever distances, the high frequencies that show this complexity are lost, however, for larger events the complexity is manifest at\n",
    "lower frequencies, meaning that we can resolve some of these complexities using seismic data. One way to resolve some of the complexity is to compute moment tensors.\n",
    "\n",
    "Read Stein and Wysession 4.4 on moment tensors.  For some information on how moment tensors are routinely computed for earthquakes in New Zealand,\n",
    "read [Ristau 2008](https://pubs.geoscienceworld.org/ssa/srl/article/79/3/400/367690/implementation-of-routine-regional-moment-tensor).  The\n",
    "moment tensors are available via the [GeoNet github page](https://github.com/GeoNet/data/tree/master/moment-tensor). You should select some\n",
    "moment tensors from the GeoNet dataset to answer the \"Slip Parameters\" question in the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
